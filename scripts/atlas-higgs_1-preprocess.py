import pandas as pd
import numpy as np
from tqdm import tqdm

# Dataset direct link: http://opendata.cern.ch/record/328/files/atlas-higgs-challenge-2014-v2.csv.gz
atlas_data = pd.read_csv("data/atlas-higgs-challenge-2014-v2.csv")
atlas_data['Label'].replace(['s', 'b'], [1, 0], inplace=True)
atlas_data.replace(-999., np.nan, inplace=True)

# Full HDF dataset
print("Saving full HDF dataset...")
atlas_data.to_hdf("data/atlas-higgs.hdf", "atlas_data", mode='w', complib='zlib', complevel=9)

# NaN classes: records can be classified based on their NaN columns
# The explanation is that this data has been generated by different processes
# 0, 1, 7, 8, 10, 11
# ^ number of NaN columns
nan_classes = atlas_data.isnull().sum(axis=1)
datasets = {}
for cls in nan_classes.unique():
    datasets[cls] = atlas_data[nan_classes == cls].dropna(axis=1)

# Kaggle sets: as separated in the original Kaggle competition
# t, b, v, u
# t: used for training
# b: used for public leaderboard
# v: used for private leaderboard
# u: unused
kaggle_sets = atlas_data.KaggleSet.unique()
for k_set in kaggle_sets:
    datasets[k_set] = atlas_data[atlas_data.KaggleSet == k_set]

with open('data/atlas-higgs_classes.txt', 'w') as f:
    f.write(','.join(map(str, datasets.keys())))

print("\nGenerating datasets...")
for key in tqdm(datasets):
    datasets[key].to_hdf("data/atlas-higgs_{}.hdf".format(key), "atlas_data", mode='w', complib='zlib', complevel=9)
